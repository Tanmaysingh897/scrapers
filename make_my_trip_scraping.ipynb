{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\n\\anaconda3\\lib\\site-packages (from selenium) (1.24.2)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading https://files.pythonhosted.org/packages/10/ed/7e8b97591f6f456174139ec089c769f89a94a1a4025fe967691de971f314/bs4-0.0.1.tar.gz\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\n\\anaconda3\\lib\\site-packages (from bs4) (4.7.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\n\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (1.8)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\n\\AppData\\Local\\pip\\Cache\\wheels\\a0\\b0\\b2\\4f80b9456b87abedbc0bf2d52235414c3467d8889be38dd472\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import selenium.webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User defined variables for data retreival\n",
    "origin = \"BOM\" \t\t\t\t# Origin airport code\n",
    "destin = \"DEL\" \t\t\t\t# Destination airport code\n",
    "trDate = \"02/09/2020\"\n",
    "\n",
    "\"\"\" The following is the Base Url for fetching data from MakeMyTrip Website.\n",
    "\tThis URL appears in the search bar after origin, destination and date inputs on the landing page.\n",
    "\tThus, this URL can be changed based on User Inputs and required data can be fetched.\n",
    "\"\"\"\n",
    "baseDataUrl = \"https://www.makemytrip.com/flight/search?itinerary=\"+ origin +\"-\"+ destin +\"-\"+ trDate +\"&tripType=O&paxType=A-1_C-0_I-0&intl=false&=&cabinClass=E\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting URL: https://www.makemytrip.com/flight/search?itinerary=BOM-DEL-02/09/2020&tripType=O&paxType=A-1_C-0_I-0&intl=false&=&cabinClass=E\n",
      "Webpage found ...\n",
      "Scrolling document upto bottom ...\n",
      "Closing Chrome ...\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(executable_path=\"C:\\\\Users\\\\n\\\\.wdm\\\\drivers\\\\chromedriver\\\\win32\\\\85.0.4183.87\\\\chromedriver\")\n",
    "print (\"Requesting URL: \" + baseDataUrl)\n",
    "driver.get(baseDataUrl)  \t\t\t # URL requested in browser.\n",
    "print (\"Webpage found ...\")\n",
    "element_xpath = '//*[@id=\"left-side--wrapper\"]/div[2]'\n",
    "element = WebDriverWait(driver, 15).until(EC.visibility_of_element_located((By.XPATH, element_xpath)))\n",
    "print (\"Scrolling document upto bottom ...\")\n",
    "for j in range(1, 100):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "body = driver.find_element_by_tag_name(\"body\").get_attribute(\"innerHTML\")\n",
    "print(\"Closing Chrome ...\") # No more usage needed.\n",
    "driver.quit() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data from DOM ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting data from DOM ...\")\n",
    "soupBody = BeautifulSoup(body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getting flight details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "Details=soupBody.find_all(lambda tag: tag.name == 'span' and tag.get('class') == ['pull-right'])\n",
    "time=list()\n",
    "total_fare=list()\n",
    "base_fare=list()\n",
    "for i in range(0,len(Details),4):\n",
    "    time.append(Details[i].text)\n",
    "for i in range(1,len(Details),4):\n",
    "    total_fare.append(Details[i].text)\n",
    "for i in range(2,len(Details),4):\n",
    "    base_fare.append(Details[i].text)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# airline name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go Air', 'Vistara', 'Vistara', 'Vistara', 'Vistara', 'Spicejet', 'Spicejet', 'Air India', 'Air India', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'AirAsia', 'AirAsia', 'IndiGo', 'IndiGo', 'IndiGo', 'Air India', 'IndiGo', 'IndiGo', 'IndiGo', 'Vistara', 'IndiGo', 'IndiGo', 'Air India', 'IndiGo', 'IndiGo', 'Vistara', 'Air India', 'Vistara', 'Vistara', 'Vistara', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'Spicejet', 'Spicejet', 'Spicejet']\n"
     ]
    }
   ],
   "source": [
    "airline_name_container=soupBody.find_all(\"span\",{\"class\":\"airways-name\"})\n",
    "airline_name=list()\n",
    "for i in range(0,len(airline_name_container)):\n",
    "    airline_name.append(airline_name_container[i].text)\n",
    "print(airline_name)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Non stop', 'Non stop', 'Non stop', 'Non stop', 'Non stop', 'Non stop', 'Non stop', 'Non stop', 'Non stop', 'Non stop', 'Non stop', 'Non stop', 'Non stop', 'Non stop', '1 stop via Bengaluru', '1 stop via Hyderabad', '1 stop via Lucknow', '1 stop via Hyderabad', '1 stop via Hyderabad', '1 stop via Hyderabad', '1 stop via Hyderabad', '1 stop via Hyderabad', '1 stop via Hyderabad', '1 stop via Hyderabad', '1 stop via Hyderabad', '1 stop via Goa', '1 stop via Bhubaneswar', '1 stop via Dehradun', '1 stop via Dehradun', '1 stop via Bengaluru', '2 stop via Bengaluru,Lucknow', '1 stop via Bengaluru', '1 stop via Chennai', '1 stop via Chennai', '1 stop via Nagpur', '1 stop via Ahmedabad', '1 stop via Raipur', '1 stop via Varanasi', '1 stop via Allahabad', '1 stop via Gorakhpur', '1 stop via Varanasi', '1 stop via Patna']\n"
     ]
    }
   ],
   "source": [
    "stop_container=soupBody.find_all(\"p\",{\"class\":\"fli-stops-desc\"})\n",
    "stop=list()\n",
    "for i in range(0,len(stop_container)):\n",
    "    stop.append(stop_container[i].text)\n",
    "print(stop)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai']\n"
     ]
    }
   ],
   "source": [
    "dept_container=soupBody.find_all(\"p\",{\"class\":\"dept-city\"})\n",
    "dept=list()\n",
    "for i in range(0,len(dept_container)):\n",
    "    dept.append(dept_container[i].text)\n",
    "print(dept)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi']\n"
     ]
    }
   ],
   "source": [
    "arrv_container=soupBody.find_all(\"p\",{\"class\":\"arrival-city\"})\n",
    "arrv=list()\n",
    "for i in range(0,len(arrv_container)):\n",
    "    arrv.append(arrv_container[i].text)\n",
    "print(arrv)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['08:05', '10:15', '13:30', '15:00', '17:00', '18:45', '07:20', '10:30', '21:00', '09:50', '11:35', '08:00', '15:50', '18:35', '06:00', '16:10', '14:00', '17:25', '12:00', '14:10', '09:10', '09:10', '17:25', '09:20', '12:00', '12:35', '12:00', '10:05', '10:05', '09:00', '10:30', '09:00', '09:45', '09:45', '09:50', '15:45', '06:00', '12:55', '12:45', '10:55', '06:40', '09:55']\n"
     ]
    }
   ],
   "source": [
    "dept_time_container=soupBody.find_all(\"div\",{\"class\":\"dept-time\"})\n",
    "dept_time=list()\n",
    "for i in range(0,len(dept_time_container)):\n",
    "    dept_time.append(dept_time_container[i].text)\n",
    "print(dept_time)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10:15', '12:15', '15:40', '17:10', '19:10', '20:55', '09:35', '12:45', '23:15', '11:55', '13:45', '10:15', '18:05', '20:50', '14:50', '01:00+1 DAYArrival : New Delhi03 Sep 2020', '19:45', '23:55', '20:50', '22:35', '16:15', '20:50', '22:35', '19:45', '22:35', '18:00', '21:30', '18:00', '14:50', '14:50', '21:15', '20:15', '15:15', '20:15', '17:45', '20:15', '11:25', '21:40', '19:40', '13:00+1 DAYArrival : New Delhi03 Sep 2020', '21:25', '10:40+1 DAYArrival : New Delhi03 Sep 2020']\n"
     ]
    }
   ],
   "source": [
    "arrv_time_container=soupBody.find_all(\"p\",{\"class\":\"reaching-time append_bottom3\"})\n",
    "arrv_time=list()\n",
    "for i in range(0,len(arrv_time_container)):\n",
    "    arrv_time.append(arrv_time_container[i].text)\n",
    "print(arrv_time)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['Go Air', 'Vistara', 'Vistara', 'Vistara', 'Vistara', 'Spicejet', 'Spicejet', 'Air India', 'Air India', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'AirAsia', 'AirAsia', 'IndiGo', 'IndiGo', 'IndiGo', 'Air India', 'IndiGo', 'IndiGo', 'IndiGo', 'Vistara', 'IndiGo', 'IndiGo', 'Air India', 'IndiGo', 'IndiGo', 'Vistara', 'Air India', 'Vistara', 'Vistara', 'Vistara', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'Spicejet', 'Spicejet', 'Spicejet'], ['02 hrs 10 mins ', '02 hrs ', '02 hrs 10 mins ', '02 hrs 10 mins ', '02 hrs 10 mins ', '02 hrs 10 mins ', '02 hrs 15 mins ', '02 hrs 15 mins ', '02 hrs 15 mins ', '02 hrs 05 mins ', '02 hrs 10 mins ', '02 hrs 15 mins ', '02 hrs 15 mins ', '02 hrs 15 mins ', '08 hrs 50 mins ', '08 hrs 50 mins ', '05 hrs 45 mins ', '06 hrs 30 mins ', '08 hrs 50 mins ', '08 hrs 25 mins ', '07 hrs 05 mins ', '11 hrs 40 mins ', '05 hrs 10 mins ', '10 hrs 25 mins ', '10 hrs 35 mins ', '05 hrs 25 mins ', '09 hrs 30 mins ', '07 hrs 55 mins ', '04 hrs 45 mins ', '05 hrs 50 mins ', '10 hrs 45 mins ', '11 hrs 15 mins ', '05 hrs 30 mins ', '10 hrs 30 mins ', '07 hrs 55 mins ', '04 hrs 30 mins ', '05 hrs 25 mins ', '08 hrs 45 mins ', '06 hrs 55 mins ', '26 hrs 05 mins ', '14 hrs 45 mins ', '24 hrs 45 mins '], ['₹ 4,005', '₹ 4,006', '₹ 4,006', '₹ 4,006', '₹ 4,006', '₹ 4,006', '₹ 4,006', '₹ 4,006', '₹ 4,006', '₹ 4,007', '₹ 4,007', '₹ 4,007', '₹ 4,007', '₹ 4,007', '₹ 5,313', '₹ 5,313', '₹ 6,579', '₹ 6,579', '₹ 6,579', '₹ 6,631', '₹ 6,737', '₹ 6,737', '₹ 6,841', '₹ 6,841', '₹ 6,841', '₹ 7,523', '₹ 7,681', '₹ 8,050', '₹ 8,207', '₹ 8,424', '₹ 8,424', '₹ 8,424', '₹ 8,731', '₹ 8,731', '₹ 8,833', '₹ 10,831', '₹ 10,831', '₹ 10,831', '₹ 11,399', '₹ 12,722', '₹ 12,914', '₹ 14,403'], ['₹ 2,619', '₹ 3,370', '₹ 3,370', '₹ 3,370', '₹ 3,370', '₹ 3,371', '₹ 3,371', '₹ 3,330', '₹ 3,330', '₹ 3,400', '₹ 3,400', '₹ 3,400', '₹ 3,400', '₹ 3,400', '₹ 4,669', '₹ 4,669', '₹ 5,800', '₹ 5,800', '₹ 5,800', '₹ 5,660', '₹ 5,950', '₹ 5,950', '₹ 6,050', '₹ 5,940', '₹ 6,050', '₹ 6,700', '₹ 6,660', '₹ 7,201', '₹ 7,350', '₹ 7,240', '₹ 7,160', '₹ 7,240', '₹ 7,740', '₹ 7,740', '₹ 7,948', '₹ 9,850', '₹ 9,850', '₹ 9,850', '₹ 10,440', '₹ 11,671', '₹ 11,855', '₹ 13,272'], ['Non stop', 'Non stop', 'Non stop', 'Non stop', 'Non stop', 'Non stop', 'Non stop', 'Non stop', 'Non stop', 'Non stop', 'Non stop', 'Non stop', 'Non stop', 'Non stop', '1 stop via Bengaluru', '1 stop via Hyderabad', '1 stop via Lucknow', '1 stop via Hyderabad', '1 stop via Hyderabad', '1 stop via Hyderabad', '1 stop via Hyderabad', '1 stop via Hyderabad', '1 stop via Hyderabad', '1 stop via Hyderabad', '1 stop via Hyderabad', '1 stop via Goa', '1 stop via Bhubaneswar', '1 stop via Dehradun', '1 stop via Dehradun', '1 stop via Bengaluru', '2 stop via Bengaluru,Lucknow', '1 stop via Bengaluru', '1 stop via Chennai', '1 stop via Chennai', '1 stop via Nagpur', '1 stop via Ahmedabad', '1 stop via Raipur', '1 stop via Varanasi', '1 stop via Allahabad', '1 stop via Gorakhpur', '1 stop via Varanasi', '1 stop via Patna'], ['Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai', 'Mumbai'], ['New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi', 'New Delhi'], ['08:05', '10:15', '13:30', '15:00', '17:00', '18:45', '07:20', '10:30', '21:00', '09:50', '11:35', '08:00', '15:50', '18:35', '06:00', '16:10', '14:00', '17:25', '12:00', '14:10', '09:10', '09:10', '17:25', '09:20', '12:00', '12:35', '12:00', '10:05', '10:05', '09:00', '10:30', '09:00', '09:45', '09:45', '09:50', '15:45', '06:00', '12:55', '12:45', '10:55', '06:40', '09:55'], ['10:15', '12:15', '15:40', '17:10', '19:10', '20:55', '09:35', '12:45', '23:15', '11:55', '13:45', '10:15', '18:05', '20:50', '14:50', '01:00+1 DAYArrival : New Delhi03 Sep 2020', '19:45', '23:55', '20:50', '22:35', '16:15', '20:50', '22:35', '19:45', '22:35', '18:00', '21:30', '18:00', '14:50', '14:50', '21:15', '20:15', '15:15', '20:15', '17:45', '20:15', '11:25', '21:40', '19:40', '13:00+1 DAYArrival : New Delhi03 Sep 2020', '21:25', '10:40+1 DAYArrival : New Delhi03 Sep 2020']]]\n"
     ]
    }
   ],
   "source": [
    "flight_booking=[]\n",
    "flight_booking.append([airline_name,time,total_fare,base_fare,stop,dept,arrv,dept_time,arrv_time])\n",
    "print(flight_booking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data1=pd.DataFrame(data={'airline':airline_name,'time':time,\"price\":total_fare,\"base_price\":base_fare,\"stops\":stop,\"source\":dept,\"destination\":arrv,\"dept_time\":dept_time,\"arrv_time\":arrv_time})\n",
    "data1['date']=trDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=data1.columns\n",
    "final_data=pd.DataFrame(columns=col)\n",
    "final_data=final_data.append(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting URL: https://www.makemytrip.com/flight/search?itinerary=BOM-DEL-02/09/2020&tripType=O&paxType=A-1_C-0_I-0&intl=false&=&cabinClass=E\n",
      "Webpage found ...\n",
      "Scrolling document upto bottom ...\n",
      "Closing Chrome ...\n",
      "Getting data from DOM ...\n",
      "Requesting URL: https://www.makemytrip.com/flight/search?itinerary=BOM-DEL-03/09/2020&tripType=O&paxType=A-1_C-0_I-0&intl=false&=&cabinClass=E\n",
      "Webpage found ...\n",
      "Scrolling document upto bottom ...\n",
      "Closing Chrome ...\n",
      "Getting data from DOM ...\n",
      "Requesting URL: https://www.makemytrip.com/flight/search?itinerary=BOM-DEL-04/09/2020&tripType=O&paxType=A-1_C-0_I-0&intl=false&=&cabinClass=E\n",
      "Webpage found ...\n",
      "Scrolling document upto bottom ...\n",
      "Closing Chrome ...\n",
      "Getting data from DOM ...\n",
      "Requesting URL: https://www.makemytrip.com/flight/search?itinerary=BOM-DEL-05/09/2020&tripType=O&paxType=A-1_C-0_I-0&intl=false&=&cabinClass=E\n",
      "Webpage found ...\n",
      "Scrolling document upto bottom ...\n",
      "Closing Chrome ...\n",
      "Getting data from DOM ...\n",
      "Requesting URL: https://www.makemytrip.com/flight/search?itinerary=BOM-DEL-06/09/2020&tripType=O&paxType=A-1_C-0_I-0&intl=false&=&cabinClass=E\n",
      "Webpage found ...\n",
      "Scrolling document upto bottom ...\n",
      "Closing Chrome ...\n",
      "Getting data from DOM ...\n",
      "Requesting URL: https://www.makemytrip.com/flight/search?itinerary=BOM-DEL-07/09/2020&tripType=O&paxType=A-1_C-0_I-0&intl=false&=&cabinClass=E\n",
      "Webpage found ...\n",
      "Scrolling document upto bottom ...\n",
      "Closing Chrome ...\n",
      "Getting data from DOM ...\n",
      "Requesting URL: https://www.makemytrip.com/flight/search?itinerary=BOM-DEL-08/09/2020&tripType=O&paxType=A-1_C-0_I-0&intl=false&=&cabinClass=E\n",
      "Webpage found ...\n",
      "Scrolling document upto bottom ...\n",
      "Closing Chrome ...\n",
      "Getting data from DOM ...\n",
      "Requesting URL: https://www.makemytrip.com/flight/search?itinerary=BOM-DEL-09/09/2020&tripType=O&paxType=A-1_C-0_I-0&intl=false&=&cabinClass=E\n",
      "Webpage found ...\n",
      "Scrolling document upto bottom ...\n",
      "Closing Chrome ...\n",
      "Getting data from DOM ...\n",
      "Requesting URL: https://www.makemytrip.com/flight/search?itinerary=BOM-DEL-10/09/2020&tripType=O&paxType=A-1_C-0_I-0&intl=false&=&cabinClass=E\n",
      "Webpage found ...\n",
      "Scrolling document upto bottom ...\n",
      "Closing Chrome ...\n",
      "Getting data from DOM ...\n",
      "Requesting URL: https://www.makemytrip.com/flight/search?itinerary=BOM-DEL-11/09/2020&tripType=O&paxType=A-1_C-0_I-0&intl=false&=&cabinClass=E\n",
      "Webpage found ...\n",
      "Scrolling document upto bottom ...\n",
      "Closing Chrome ...\n",
      "Getting data from DOM ...\n",
      "Requesting URL: https://www.makemytrip.com/flight/search?itinerary=BOM-DEL-12/09/2020&tripType=O&paxType=A-1_C-0_I-0&intl=false&=&cabinClass=E\n",
      "Webpage found ...\n",
      "Scrolling document upto bottom ...\n",
      "Closing Chrome ...\n",
      "Getting data from DOM ...\n",
      "Requesting URL: https://www.makemytrip.com/flight/search?itinerary=BOM-DEL-13/09/2020&tripType=O&paxType=A-1_C-0_I-0&intl=false&=&cabinClass=E\n",
      "Webpage found ...\n",
      "Scrolling document upto bottom ...\n",
      "Closing Chrome ...\n",
      "Getting data from DOM ...\n",
      "Requesting URL: https://www.makemytrip.com/flight/search?itinerary=BOM-DEL-14/09/2020&tripType=O&paxType=A-1_C-0_I-0&intl=false&=&cabinClass=E\n",
      "Webpage found ...\n",
      "Scrolling document upto bottom ...\n",
      "Closing Chrome ...\n",
      "Getting data from DOM ...\n",
      "Requesting URL: https://www.makemytrip.com/flight/search?itinerary=BOM-DEL-15/09/2020&tripType=O&paxType=A-1_C-0_I-0&intl=false&=&cabinClass=E\n",
      "Webpage found ...\n",
      "Scrolling document upto bottom ...\n",
      "Closing Chrome ...\n",
      "Getting data from DOM ...\n"
     ]
    }
   ],
   "source": [
    "dates=[\"02/09/2020\",\"03/09/2020\",\"04/09/2020\",\"05/09/2020\",\"06/09/2020\",\"07/09/2020\",\"08/09/2020\",\"09/09/2020\",\"10/09/2020\",\"11/09/2020\",\"12/09/2020\",\"13/09/2020\",\"14/09/2020\",\"15/09/2020\"]\n",
    "origin = \"BOM\"\n",
    "destin = \"DEL\"\n",
    "final_data=pd.DataFrame(columns=col)\n",
    "for date in dates:\n",
    "    trDate=date\n",
    "    baseDataUrl = \"https://www.makemytrip.com/flight/search?itinerary=\"+ origin +\"-\"+ destin +\"-\"+ trDate +\"&tripType=O&paxType=A-1_C-0_I-0&intl=false&=&cabinClass=E\"\n",
    "    driver = webdriver.Chrome(executable_path=\"C:\\\\Users\\\\n\\\\.wdm\\\\drivers\\\\chromedriver\\\\win32\\\\85.0.4183.87\\\\chromedriver\")\n",
    "    print (\"Requesting URL: \" + baseDataUrl)\n",
    "    driver.get(baseDataUrl)  # URL requested in browser.\n",
    "    print (\"Webpage found ...\")\n",
    "    element_xpath = '//*[@id=\"left-side--wrapper\"]/div[2]'\n",
    "    element = WebDriverWait(driver, 15).until(EC.visibility_of_element_located((By.XPATH, element_xpath)))\n",
    "    print (\"Scrolling document upto bottom ...\")\n",
    "    for j in range(1, 100):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    body = driver.find_element_by_tag_name(\"body\").get_attribute(\"innerHTML\")\n",
    "    print(\"Closing Chrome ...\") # No more usage needed.\n",
    "    driver.quit() \n",
    "    print(\"Getting data from DOM ...\")\n",
    "    soupBody = BeautifulSoup(body)\n",
    "    Details=soupBody.find_all(lambda tag: tag.name == 'span' and tag.get('class') == ['pull-right'])\n",
    "    time=list()\n",
    "    total_fare=list()\n",
    "    base_fare=list()\n",
    "    for i in range(0,len(Details),4):\n",
    "        time.append(Details[i].text)\n",
    "    for i in range(1,len(Details),4):\n",
    "        total_fare.append(Details[i].text)\n",
    "    for i in range(2,len(Details),4):\n",
    "        base_fare.append(Details[i].text)\n",
    "    airline_name_container=soupBody.find_all(\"span\",{\"class\":\"airways-name\"})\n",
    "    airline_name=list()\n",
    "    for i in range(0,len(airline_name_container)):\n",
    "        airline_name.append(airline_name_container[i].text)\n",
    "    stop_container=soupBody.find_all(\"p\",{\"class\":\"fli-stops-desc\"})\n",
    "    stop=list()\n",
    "    for i in range(0,len(stop_container)):\n",
    "        stop.append(stop_container[i].text)\n",
    "    dept_container=soupBody.find_all(\"p\",{\"class\":\"dept-city\"})\n",
    "    dept=list()\n",
    "    arrv_container=soupBody.find_all(\"p\",{\"class\":\"arrival-city\"})\n",
    "    arrv=list()\n",
    "    for i in range(0,len(arrv_container)):\n",
    "        arrv.append(arrv_container[i].text)\n",
    "    for i in range(0,len(dept_container)):\n",
    "        dept.append(dept_container[i].text)\n",
    "    arrv_time_container=soupBody.find_all(\"p\",{\"class\":\"reaching-time append_bottom3\"})\n",
    "    arrv_time=list()\n",
    "    for i in range(0,len(arrv_time_container)):\n",
    "        arrv_time.append(arrv_time_container[i].text)\n",
    "    dept_time_container=soupBody.find_all(\"div\",{\"class\":\"dept-time\"})\n",
    "    dept_time=list()\n",
    "    for i in range(0,len(dept_time_container)):\n",
    "        dept_time.append(dept_time_container[i].text) \n",
    "    data1=pd.DataFrame(data={'airline':airline_name,'time':time,\"price\":total_fare,\"base_price\":base_fare,\"stops\":stop,\"source\":dept,\"destination\":arrv,\"dept_time\":dept_time,\"arrv_time\":arrv_time})\n",
    "    data1['date']=trDate\n",
    "    data1['class']='Economy'\n",
    "    col=data1.columns\n",
    "    final_data=final_data.append(data1)#only drawback is you need to know column name before hand in order to make empty dataframe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv(\"economy_class_DEL_BOM.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>arrv_time</th>\n",
       "      <th>base_price</th>\n",
       "      <th>class</th>\n",
       "      <th>date</th>\n",
       "      <th>dept_time</th>\n",
       "      <th>destination</th>\n",
       "      <th>price</th>\n",
       "      <th>source</th>\n",
       "      <th>stops</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go Air</td>\n",
       "      <td>10:15</td>\n",
       "      <td>₹ 2,619</td>\n",
       "      <td>Economy</td>\n",
       "      <td>02/09/2020</td>\n",
       "      <td>08:05</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>₹ 4,005</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Non stop</td>\n",
       "      <td>02 hrs 10 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>12:15</td>\n",
       "      <td>₹ 3,370</td>\n",
       "      <td>Economy</td>\n",
       "      <td>02/09/2020</td>\n",
       "      <td>10:15</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>₹ 4,006</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Non stop</td>\n",
       "      <td>02 hrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>15:40</td>\n",
       "      <td>₹ 3,370</td>\n",
       "      <td>Economy</td>\n",
       "      <td>02/09/2020</td>\n",
       "      <td>13:30</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>₹ 4,006</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Non stop</td>\n",
       "      <td>02 hrs 10 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>17:10</td>\n",
       "      <td>₹ 3,370</td>\n",
       "      <td>Economy</td>\n",
       "      <td>02/09/2020</td>\n",
       "      <td>15:00</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>₹ 4,006</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Non stop</td>\n",
       "      <td>02 hrs 10 mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>19:10</td>\n",
       "      <td>₹ 3,370</td>\n",
       "      <td>Economy</td>\n",
       "      <td>02/09/2020</td>\n",
       "      <td>17:00</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>₹ 4,006</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Non stop</td>\n",
       "      <td>02 hrs 10 mins</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   airline arrv_time base_price    class        date dept_time destination  \\\n",
       "0   Go Air     10:15    ₹ 2,619  Economy  02/09/2020     08:05   New Delhi   \n",
       "1  Vistara     12:15    ₹ 3,370  Economy  02/09/2020     10:15   New Delhi   \n",
       "2  Vistara     15:40    ₹ 3,370  Economy  02/09/2020     13:30   New Delhi   \n",
       "3  Vistara     17:10    ₹ 3,370  Economy  02/09/2020     15:00   New Delhi   \n",
       "4  Vistara     19:10    ₹ 3,370  Economy  02/09/2020     17:00   New Delhi   \n",
       "\n",
       "     price  source     stops             time  \n",
       "0  ₹ 4,005  Mumbai  Non stop  02 hrs 10 mins   \n",
       "1  ₹ 4,006  Mumbai  Non stop          02 hrs   \n",
       "2  ₹ 4,006  Mumbai  Non stop  02 hrs 10 mins   \n",
       "3  ₹ 4,006  Mumbai  Non stop  02 hrs 10 mins   \n",
       "4  ₹ 4,006  Mumbai  Non stop  02 hrs 10 mins   "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "addinfo=soupBody.findAll(\"div\",{\"class\":\"flight_details__infoSctn\"})\n",
    "add=list()\n",
    "for i in range(len(addinfo)):\n",
    "    add.append(addinfo[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Go Air', 'Go Air', 'Vistara', 'Vistara', 'Vistara', 'Vistara', 'Spicejet', 'Air India', 'Spicejet', 'Air India', 'Air India', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'AirAsia', 'Spicejet', 'Spicejet', 'Spicejet', 'Spicejet', 'Spicejet', 'Spicejet', 'Spicejet', 'Spicejet', 'Spicejet', 'Spicejet', 'Spicejet', 'Spicejet', 'Spicejet', 'Spicejet', 'Spicejet', 'Spicejet', 'Spicejet', 'Spicejet', 'Spicejet', 'Spicejet', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'IndiGo', 'Vistara', 'Vistara', 'IndiGo', 'Vistara', 'Air India', 'Vistara', 'Vistara', 'Vistara', 'Vistara', 'Spicejet']\n"
     ]
    }
   ],
   "source": [
    "airline_name_container=soupBody.find_all(\"span\",{\"class\":\"airways-name\"})\n",
    "airline_name=list()\n",
    "for i in range(0,len(airline_name_container)):\n",
    "    airline_name.append(airline_name_container[i].text)\n",
    "print(airline_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(addinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
